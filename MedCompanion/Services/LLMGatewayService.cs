using System;
using System.Collections.Generic;
using System.Threading;
using System.Threading.Tasks;
using MedCompanion.Models;
using MedCompanion.Services.LLM;

namespace MedCompanion.Services
{
    /// <summary>
    /// Service passerelle centralis√© pour tous les appels LLM.
    /// G√®re automatiquement l'anonymisation selon le type de provider :
    /// - Local (Ollama) : Pas d'anonymisation
    /// - Cloud (OpenAI) : Anonymisation 3 phases + D√©sanonymisation
    /// </summary>
    public class LLMGatewayService
    {
        private readonly LLMServiceFactory _llmFactory;
        private readonly AnonymizationService _anonymizationService;
        private readonly OpenAIService _openAIService; // Pour ExtractPIIAsync (Phase 3)
        private readonly PathService _pathService;

        /// <summary>
        /// √âv√©nement d√©clench√© pour informer du statut
        /// </summary>
        public event EventHandler<string>? StatusChanged;

        public LLMGatewayService(
            LLMServiceFactory llmFactory,
            AnonymizationService anonymizationService,
            OpenAIService openAIService,
            PathService pathService)
        {
            _llmFactory = llmFactory ?? throw new ArgumentNullException(nameof(llmFactory));
            _anonymizationService = anonymizationService ?? throw new ArgumentNullException(nameof(anonymizationService));
            _openAIService = openAIService ?? throw new ArgumentNullException(nameof(openAIService));
            _pathService = pathService ?? throw new ArgumentNullException(nameof(pathService));
        }

        #region D√©tection Provider

        /// <summary>
        /// V√©rifie si le provider actuel est local (Ollama)
        /// </summary>
        public bool IsLocalProvider()
        {
            var providerName = _llmFactory.GetActiveProviderName();
            return providerName.Equals("Ollama", StringComparison.OrdinalIgnoreCase);
        }

        /// <summary>
        /// V√©rifie si le provider actuel est cloud (OpenAI, etc.)
        /// </summary>
        public bool IsCloudProvider()
        {
            return !IsLocalProvider();
        }

        /// <summary>
        /// Retourne le nom du provider actif
        /// </summary>
        public string GetActiveProviderName()
        {
            return _llmFactory.GetActiveProviderName();
        }

        #endregion

        #region M√©thodes principales

        /// <summary>
        /// G√©n√®re du texte avec anonymisation automatique si n√©cessaire.
        /// Pipeline : [Anonymisation 3 phases si Cloud] ‚Üí LLM ‚Üí [D√©sanonymisation si Cloud]
        /// </summary>
        /// <param name="prompt">Le prompt √† envoyer</param>
        /// <param name="patientName">Nom complet du patient (pour charger ses m√©tadonn√©es)</param>
        /// <param name="maxTokens">Nombre maximum de tokens</param>
        /// <param name="cancellationToken">Token d'annulation</param>
        /// <returns>Tuple (success, result, error)</returns>
        public async Task<(bool success, string result, string? error)> GenerateTextAsync(
            string prompt,
            string? patientName = null,
            int maxTokens = 1500,
            CancellationToken cancellationToken = default)
        {
            System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê");
            System.Diagnostics.Debug.WriteLine($"[LLMGateway] GenerateTextAsync - D√©but");
            System.Diagnostics.Debug.WriteLine($"[LLMGateway] Patient: {patientName ?? "(aucun)"}");
            System.Diagnostics.Debug.WriteLine($"[LLMGateway] Prompt: {prompt?.Length ?? 0} caract√®res");

            if (string.IsNullOrWhiteSpace(prompt))
                return (false, "", "Le prompt est vide");

            try
            {
                var llm = _llmFactory.GetCurrentProvider();
                var providerName = _llmFactory.GetActiveProviderName();
                var modelName = _llmFactory.GetActiveModelName();

                System.Diagnostics.Debug.WriteLine($"[LLMGateway] Provider: {providerName} | Model: {modelName}");

                if (!llm.IsConfigured())
                    return (false, "", "LLM non configur√©");

                // Si provider local ‚Üí Pas d'anonymisation
                if (IsLocalProvider())
                {
                    LogStatus("üñ•Ô∏è Provider local d√©tect√© - Pas d'anonymisation");
                    System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚Üí Appel direct LLM (pas d'anonymisation)");
                    var localResult = await llm.GenerateTextAsync(prompt, maxTokens);
                    System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚Üí R√©ponse: {localResult.result?.Length ?? 0} caract√®res");
                    return localResult;
                }

                // Provider cloud ‚Üí Anonymisation 3 phases
                LogStatus("‚òÅÔ∏è Provider cloud d√©tect√© - Anonymisation activ√©e");
                System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚Üí Anonymisation 3 phases activ√©e");

                var (anonymizedPrompt, context) = await AnonymizeInputAsync(prompt, patientName);

                // Appel LLM avec prompt anonymis√©
                var (success, result, error) = await llm.GenerateTextAsync(anonymizedPrompt, maxTokens);

                if (!success)
                    return (false, result, error);

                // D√©sanonymisation de la r√©ponse
                var deanonymizedResult = DeanonymizeOutput(result, context);

                return (true, deanonymizedResult, null);
            }
            catch (Exception ex)
            {
                return (false, "", $"Erreur LLMGateway: {ex.Message}");
            }
        }

        /// <summary>
        /// Chat avec historique et anonymisation automatique si n√©cessaire.
        /// Pipeline : [Anonymisation 3 phases si Cloud] ‚Üí LLM ‚Üí [D√©sanonymisation si Cloud]
        /// </summary>
        /// <param name="systemPrompt">Prompt syst√®me</param>
        /// <param name="messages">Historique des messages (role, content)</param>
        /// <param name="patientName">Nom complet du patient (pour charger ses m√©tadonn√©es)</param>
        /// <param name="maxTokens">Nombre maximum de tokens</param>
        /// <param name="cancellationToken">Token d'annulation</param>
        /// <returns>Tuple (success, result, error)</returns>
        public async Task<(bool success, string result, string? error)> ChatAsync(
            string systemPrompt,
            List<(string role, string content)> messages,
            string? patientName = null,
            int maxTokens = 1500,
            CancellationToken cancellationToken = default)
        {
            System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê");
            System.Diagnostics.Debug.WriteLine($"[LLMGateway] ChatAsync - D√©but");
            System.Diagnostics.Debug.WriteLine($"[LLMGateway] Patient: {patientName ?? "(aucun)"}");
            System.Diagnostics.Debug.WriteLine($"[LLMGateway] SystemPrompt: {systemPrompt?.Length ?? 0} caract√®res");
            System.Diagnostics.Debug.WriteLine($"[LLMGateway] Messages: {messages?.Count ?? 0} messages");

            if (messages == null || messages.Count == 0)
                return (false, "", "Aucun message fourni");

            try
            {
                // V√©rifier l'annulation d√®s le d√©but
                if (cancellationToken.IsCancellationRequested)
                    return (false, "", "Op√©ration annul√©e par l'utilisateur");

                var llm = _llmFactory.GetCurrentProvider();
                var providerName = _llmFactory.GetActiveProviderName();
                var modelName = _llmFactory.GetActiveModelName();

                System.Diagnostics.Debug.WriteLine($"[LLMGateway] Provider: {providerName} | Model: {modelName}");
                System.Diagnostics.Debug.WriteLine($"[LLMGateway] IsLocal: {IsLocalProvider()}");

                if (!llm.IsConfigured())
                    return (false, "", "LLM non configur√©");

                // Si provider local ‚Üí Pas d'anonymisation
                if (IsLocalProvider())
                {
                    LogStatus("üñ•Ô∏è Provider local d√©tect√© - Pas d'anonymisation");
                    System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚Üí Appel direct LLM (pas d'anonymisation)");

                    // V√©rifier l'annulation avant l'appel LLM
                    if (cancellationToken.IsCancellationRequested)
                        return (false, "", "Op√©ration annul√©e par l'utilisateur");

                    var localResult = await llm.ChatAsync(systemPrompt, messages, maxTokens);
                    System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚Üí R√©ponse locale: {localResult.result?.Length ?? 0} caract√®res");
                    System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê");
                    return localResult;
                }

                // Provider cloud ‚Üí Anonymisation 3 phases
                LogStatus("‚òÅÔ∏è Provider cloud d√©tect√© - Anonymisation activ√©e");
                System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚Üí Anonymisation 3 phases activ√©e");

                // V√©rifier l'annulation avant l'anonymisation
                if (cancellationToken.IsCancellationRequested)
                    return (false, "", "Op√©ration annul√©e par l'utilisateur");

                // Anonymiser le system prompt
                System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚Üí Anonymisation du system prompt...");
                var (anonymizedSystemPrompt, systemContext) = await AnonymizeInputAsync(systemPrompt, patientName);
                System.Diagnostics.Debug.WriteLine($"[LLMGateway]   SystemPrompt: {systemContext?.Replacements?.Count ?? 0} remplacements");

                // V√©rifier l'annulation apr√®s l'anonymisation du system prompt
                if (cancellationToken.IsCancellationRequested)
                    return (false, "", "Op√©ration annul√©e par l'utilisateur");

                // Anonymiser tous les messages
                System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚Üí Anonymisation de {messages.Count} messages...");
                var anonymizedMessages = new List<(string role, string content)>();
                var messagesContexts = new List<AnonymizationContext>();
                int totalReplacements = 0;

                foreach (var (role, content) in messages)
                {
                    // V√©rifier l'annulation pendant l'anonymisation des messages
                    if (cancellationToken.IsCancellationRequested)
                        return (false, "", "Op√©ration annul√©e par l'utilisateur");

                    var (anonymizedContent, msgContext) = await AnonymizeInputAsync(content, patientName);
                    anonymizedMessages.Add((role, anonymizedContent));
                    messagesContexts.Add(msgContext);
                    totalReplacements += msgContext?.Replacements?.Count ?? 0;
                }
                System.Diagnostics.Debug.WriteLine($"[LLMGateway]   Messages: {totalReplacements} remplacements au total");

                // V√©rifier l'annulation avant l'appel LLM cloud
                if (cancellationToken.IsCancellationRequested)
                    return (false, "", "Op√©ration annul√©e par l'utilisateur");

                // Appel LLM avec donn√©es anonymis√©es
                System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚Üí Appel LLM cloud avec donn√©es anonymis√©es...");
                var (success, result, error) = await llm.ChatAsync(anonymizedSystemPrompt, anonymizedMessages, maxTokens);

                // V√©rifier l'annulation apr√®s l'appel LLM
                if (cancellationToken.IsCancellationRequested)
                    return (false, "", "Op√©ration annul√©e par l'utilisateur");

                if (!success)
                {
                    System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚úó Erreur LLM: {error}");
                    return (false, result, error);
                }

                System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚úì R√©ponse cloud: {result?.Length ?? 0} caract√®res");

                // D√©sanonymisation de la r√©ponse (utiliser le contexte combin√©)
                System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚Üí D√©sanonymisation de la r√©ponse...");
                var combinedContext = CombineContexts(systemContext, messagesContexts);
                System.Diagnostics.Debug.WriteLine($"[LLMGateway]   Contexte combin√©: {combinedContext?.Replacements?.Count ?? 0} remplacements");
                var deanonymizedResult = DeanonymizeOutput(result, combinedContext);
                System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚úì D√©sanonymisation termin√©e");
                System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê");

                return (true, deanonymizedResult, null);
            }
            catch (OperationCanceledException)
            {
                System.Diagnostics.Debug.WriteLine($"[LLMGateway] ‚úó Op√©ration annul√©e");
                return (false, "", "Op√©ration annul√©e par l'utilisateur");
            }
            catch (Exception ex)
            {
                return (false, "", $"Erreur LLMGateway: {ex.Message}");
            }
        }

        #endregion

        #region Anonymisation 3 phases

        /// <summary>
        /// Anonymise le texte avec les 3 phases :
        /// Phase 1 : Donn√©es patient.json
        /// Phase 2 : Patterns regex
        /// Phase 3 : Extraction LLM local (si disponible)
        /// </summary>
        private async Task<(string anonymizedText, AnonymizationContext context)> AnonymizeInputAsync(
            string text,
            string? patientName)
        {
            if (string.IsNullOrWhiteSpace(text))
                return (text ?? "", new AnonymizationContext());

            var context = new AnonymizationContext { WasAnonymized = true };

            // Charger les m√©tadonn√©es patient si disponible
            PatientMetadata? patientData = null;
            if (!string.IsNullOrWhiteSpace(patientName))
            {
                patientData = LoadPatientMetadata(patientName);
            }

            // Phase 3 : Extraction PII via LLM local (si Ollama disponible)
            PIIExtractionResult? extractedPii = null;
            try
            {
                // V√©rifier si Ollama est disponible pour l'extraction
                if (await _llmFactory.IsOllamaAvailableAsync())
                {
                    LogStatus("üîç Phase 3 - Extraction PII via LLM local...");
                    extractedPii = await _openAIService.ExtractPIIAsync(text);

                    if (extractedPii != null && extractedPii.GetAllEntities().Count > 0)
                    {
                        System.Diagnostics.Debug.WriteLine($"[LLMGateway] Phase 3 - {extractedPii.GetAllEntities().Count} entit√©s extraites");
                    }
                }
            }
            catch (Exception ex)
            {
                System.Diagnostics.Debug.WriteLine($"[LLMGateway] Phase 3 √©chou√©e (non bloquant): {ex.Message}");
            }

            // Appliquer l'anonymisation avec les 3 phases
            string anonymizedText;

            if (extractedPii != null || patientData != null)
            {
                // Utiliser AnonymizeWithExtractedData qui combine les 3 phases
                anonymizedText = _anonymizationService.AnonymizeWithExtractedData(
                    text,
                    extractedPii,   // Phase 3
                    patientData,    // Phase 1
                    context         // Phase 2 inclus
                );
            }
            else
            {
                // Fallback : Phase 1+2 seulement
                var (anonText, anonContext) = await _anonymizationService.AnonymizeAsync(text, patientData);
                anonymizedText = anonText;
                context = anonContext;
            }

            LogStatus($"‚úì Anonymisation termin√©e ({context.Replacements.Count} remplacements)");

            return (anonymizedText, context);
        }

        /// <summary>
        /// Charge les m√©tadonn√©es patient depuis patient.json
        /// </summary>
        private PatientMetadata? LoadPatientMetadata(string patientName)
        {
            try
            {
                var patientJsonPath = _pathService.GetPatientJsonPath(patientName);

                if (System.IO.File.Exists(patientJsonPath))
                {
                    var json = System.IO.File.ReadAllText(patientJsonPath, System.Text.Encoding.UTF8);
                    return System.Text.Json.JsonSerializer.Deserialize<PatientMetadata>(json);
                }
            }
            catch (Exception ex)
            {
                System.Diagnostics.Debug.WriteLine($"[LLMGateway] Erreur chargement patient.json: {ex.Message}");
            }

            return null;
        }

        #endregion

        #region D√©sanonymisation

        /// <summary>
        /// D√©sanonymise la r√©ponse du LLM
        /// </summary>
        private string DeanonymizeOutput(string text, AnonymizationContext? context)
        {
            if (string.IsNullOrWhiteSpace(text) || context == null || !context.WasAnonymized)
                return text;

            return _anonymizationService.Deanonymize(text, context);
        }

        /// <summary>
        /// Combine plusieurs contextes d'anonymisation en un seul
        /// </summary>
        private AnonymizationContext CombineContexts(AnonymizationContext? systemContext, List<AnonymizationContext> messagesContexts)
        {
            var combined = new AnonymizationContext { WasAnonymized = true };

            // Ajouter les remplacements du system prompt
            if (systemContext?.Replacements != null)
            {
                foreach (var kvp in systemContext.Replacements)
                {
                    if (!combined.Replacements.ContainsKey(kvp.Key))
                        combined.Replacements[kvp.Key] = kvp.Value;
                }
                combined.Pseudonym = systemContext.Pseudonym;
            }

            // Ajouter les remplacements de chaque message
            foreach (var msgContext in messagesContexts)
            {
                if (msgContext?.Replacements != null)
                {
                    foreach (var kvp in msgContext.Replacements)
                    {
                        if (!combined.Replacements.ContainsKey(kvp.Key))
                            combined.Replacements[kvp.Key] = kvp.Value;
                    }

                    // Garder le pseudonyme s'il existe
                    if (!string.IsNullOrEmpty(msgContext.Pseudonym))
                        combined.Pseudonym = msgContext.Pseudonym;
                }
            }

            return combined;
        }

        #endregion

        #region Helpers

        private void LogStatus(string message)
        {
            System.Diagnostics.Debug.WriteLine($"[LLMGateway] {message}");
            StatusChanged?.Invoke(this, message);
        }

        #endregion
    }
}
